# -*- coding: utf-8 -*-
"""caseStudy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AzMxHit4GV_kFoEn6ltqh3qm4GXbBMQW
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df1=pd.read_csv("left employee.csv")
df1.head()

df1[['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','promotion_last_5years']].describe()



df=pd.read_csv("Existing EmployeesX.csv")
df.head(n=10)

ax = sns.catplot(y='satisfaction_level',x='dept',hue='Existing or Left',kind='point',data=df)
ax.fig.autofmt_xdate()

ax = sns.catplot(y='last_evaluation',x='dept',hue='Existing or Left',kind='point',data=df)
ax.fig.autofmt_xdate()

ax = sns.catplot(y='number_project',x='dept',hue='Existing or Left',kind='box',data=df)
ax.fig.autofmt_xdate()
# sns.catplot(x="day", y="total_bill", hue="sex", kind="box", data=tips);

ax = sns.catplot(y='average_montly_hours',x='dept',hue='Existing or Left',kind='point',data=df)
ax.fig.autofmt_xdate()

ax = sns.catplot(y='time_spend_company',x='dept',hue='Existing or Left',kind='point',data=df)
ax.fig.autofmt_xdate()

ax = sns.catplot(y='Work_accident',x='dept',hue='Existing or Left',kind='point',data=df)
ax.fig.autofmt_xdate()

ax = sns.catplot(y='promotion_last_5years',x='dept',hue='Existing or Left',kind='point',data=df)
ax.fig.autofmt_xdate()

import matplotlib.ticker as mtick
df.groupby(['salary','Existing or Left']).size().groupby(level=0).apply(
    lambda x: 100 * x / x.sum()).unstack().plot(kind='bar',stacked=True, figsize=(10,6))

plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())
plt.show()

import matplotlib.ticker as mtick
df.groupby(['dept','Existing or Left']).size().groupby(level=0).apply(
    lambda x: 100 * x / x.sum()).unstack().plot(kind='bar',stacked=True, figsize=(10,6))

plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())
plt.show()

import matplotlib.ticker as mtick
df.groupby(['Existing or Left','salary','dept']).size().groupby(level=0).apply(
    lambda x: 100 * x / x.sum()).unstack().plot(kind='bar',stacked=True,figsize=(14,10))

plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())
plt.show()



df['dept'].value_counts()

d4={'low':100,'medium':50,'high':25}
df['salary']=df['salary'].map(d4)

df1=pd.get_dummies(df,prefix=['dept'])
df1.head()

def heatmap(x, y, size):
    fig, ax = plt.subplots(figsize=(9,9))
    
    # Mapping from column names to integer coordinates
    x_labels = [v for v in sorted(x.unique())]
    y_labels = [v for v in sorted(y.unique())]
    x_to_num = {p[1]:p[0] for p in enumerate(x_labels)} 
    y_to_num = {p[1]:p[0] for p in enumerate(y_labels)} 
    
    size_scale = 350
    ax.scatter(
        x=x.map(x_to_num), # Use mapping for x
        y=y.map(y_to_num), # Use mapping for y
        s=size * size_scale, # Vector of square sizes, proportional to size parameter
        marker='s' # Use square as scatterplot marker
        
    )
    
    ax.grid(False, 'major')
    ax.grid(True, 'minor')
    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)
    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)

    # Show column labels on the axes
    ax.set_xticks([x_to_num[v] for v in x_labels])
    ax.set_xticklabels(x_labels, rotation=45, horizontalalignment='right')
    ax.set_yticks([y_to_num[v] for v in y_labels])
    ax.set_yticklabels(y_labels)
features=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','promotion_last_5years','salary','dept_IT','dept_RandD','dept_accounting','dept_hr','dept_management','dept_marketing','dept_product_mng','dept_sales','dept_support','dept_technical','Existing or Left']
corr = df1[features].corr()
corr = pd.melt(corr.reset_index(), id_vars='index') # Unpivot the dataframe, so we can get pair of arrays for x and y
corr.columns = ['x', 'y', 'value']
heatmap(
    x=corr['x'],
    y=corr['y'],
    size=corr['value'].abs()*2
)

features=['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','promotion_last_5years','salary','dept_IT','dept_RandD','dept_accounting','dept_hr','dept_management','dept_marketing','dept_product_mng','dept_sales','dept_support','dept_technical']
X=df1[features]
y=df1['Existing or Left']

scaler = StandardScaler().fit(X)
x = scaler.transform(X)

from sklearn.model_selection import train_test_split
trainx,testx,trainy,testy=train_test_split(X,y,test_size=0.25,random_state=0)

from sklearn.svm import SVC
clf=SVC(kernel='rbf')
clf.fit(trainx,trainy)

ypredict=clf.predict(testx)
clf.score(testx,testy)

clf1 = RandomForestClassifier()
clf1.fit(trainx, trainy)
clf1.score(trainx,trainy)

param_grid = {
    'n_estimators': [21, 20,22],
    'max_depth': [23,24, 21,20]
}
gridsearch = GridSearchCV(RandomForestClassifier(n_jobs = -1), 
                          param_grid=param_grid, 
                          scoring='accuracy', cv=3, 
                          return_train_score=True, verbose=10)
gridsearch.fit(trainx,trainy)

pd.DataFrame(gridsearch.cv_results_).sort_values(by='rank_test_score')

clf1  = RandomForestClassifier(max_depth = 21, 
                             n_estimators = 22, 
                             n_jobs = -1,random_state=1)
clf1.fit(trainx, trainy)
clf1.score(testx,testy)

df2=pd.read_csv("Existing.csv")
df2.head()

y10=df2['dept']
y11=df2['salary']

d4={'low':100,'medium':50,'high':25}
df2['salary']=df2['salary'].map(d4)
df2=pd.get_dummies(df2,prefix=['dept'])

# from sklearn.model_selection import cross_val_score, cross_val_predict
# y=cross_val_predict(clf1, df2[features],y, cv=6)
 y=clf1.predict(df2[features])
y

features1=['Emp ID','satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','promotion_last_5years']
df3=df2[features1]
df3['salary']=y11
df3['dept']=y10
df3['Existing or Left']=y
df3.head()

df3.to_csv('Future_leftX.csv')

